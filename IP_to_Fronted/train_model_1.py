"""
æœè£åˆ†é¡æ¨¡å‹è¨“ç·´è…³æœ¬ (CPU/GPU ç‰ˆæœ¬)
æ”¯æŒ GPU é‹ç®—ï¼Œè‹¥ç„¡ GPU è‡ªå‹•é™ç´šåˆ° CPU
"""

import os
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import models, transforms
from PIL import Image
import matplotlib.pyplot as plt
import subprocess
import sys

# ============================================================
# 1. åˆå§‹åŒ–ç’°å¢ƒèˆ‡ä¸‹è¼‰è³‡æ–™
# ============================================================

def setup_kaggle_and_download():
    """è¨­å®š Kaggle API ä¸¦ä¸‹è¼‰è³‡æ–™"""
    KAGGLE_TOKEN = "KGAT_3270ac64ff39696c1ec0b890d8d5cdca"
    
    # è¨­å®šç’°å¢ƒè®Šæ•¸
    os.environ['KAGGLE_USERNAME'] = "RedTimesZero"
    os.environ['KAGGLE_KEY'] = KAGGLE_TOKEN

    # åœ–ç‰‡è³‡æ–™å¤¾ä¸å­˜åœ¨å‰‡ä¸‹è¼‰è³‡æ–™é›†
    if not os.path.exists('images'):
        print("æ­£åœ¨ä¸‹è¼‰è³‡æ–™é›†...")
        try:
            subprocess.run([sys.executable, "-m", "pip", "install", "kaggle", "-q"])
            subprocess.run(["kaggle", "datasets", "download", "-d", "paramaggarwal/fashion-product-images-small"], check=True)
            
            # Windows ç”¨ PowerShell è§£å£“ ZIP
            import zipfile
            with zipfile.ZipFile('fashion-product-images-small.zip', 'r') as zip_ref:
                zip_ref.extractall('.')
            print("âœ… ä¸‹è¼‰å®Œæˆï¼")
        except Exception as e:
            print(f"âŒ ä¸‹è¼‰å¤±æ•—: {e}")
            print("è«‹æ‰‹å‹•å¾ Kaggle ä¸‹è¼‰è³‡æ–™é›†ä¸¦è§£å£“: https://www.kaggle.com/paramaggarwal/fashion-product-images-small")
            print("ç¢ºä¿è§£å£“å¾Œæœ‰ images/ è³‡æ–™å¤¾")
    else:
        print("âœ… è³‡æ–™é›†å·²å­˜åœ¨ï¼Œè·³éä¸‹è¼‰")


def load_and_prepare_data():
    """è®€å–èˆ‡ç¯©é¸è³‡æ–™"""
    print("æ­£åœ¨è™•ç†è³‡æ–™...")
    if not os.path.exists('styles.csv'):
        print("âŒ styles.csv ä¸å­˜åœ¨ï¼Œè«‹å…ˆåŸ·è¡Œ remove_tops.py")
        sys.exit(1)
    df = pd.read_csv('styles.csv', on_bad_lines='skip')

    # æ¸…ç†æ¬„ä½
    df.columns = [c.strip() for c in df.columns]
    df['gender'] = df['gender'].astype(str).str.strip()
    df['articleType'] = df['articleType'].astype(str).str.strip()
    df['baseColour'] = df['baseColour'].astype(str).str.strip()

    # ç¯©é¸ Women çš„æœé£¾ (ç”¨ articleType ä½œç‚ºç´°åˆ†é¡)
    filtered_df = df[
        (df['gender'] == 'Women') &
        (df['articleType'].notna())
    ].copy()

    # ç¢ºä¿ ID æ­£ç¢º
    filtered_df['id'] = pd.to_numeric(filtered_df['id'], errors='coerce').fillna(0).astype(int)

    # å»ºç«‹æ¨™ç±¤æ˜ å°„ (ç”¨ articleType è€Œä¸æ˜¯ subCategory)
    filtered_df['cat_label'], cat_uniques = pd.factorize(filtered_df['articleType'])
    filtered_df['color_label'], color_uniques = pd.factorize(filtered_df['baseColour'])

    cat_map = dict(enumerate(cat_uniques))
    color_map = dict(enumerate(color_uniques))

    print(f"è³‡æ–™æº–å‚™å®Œæˆï¼æ¨£æœ¬æ•¸: {len(filtered_df)}")
    print(f"æœè£é¡å‹: {list(cat_uniques)}")
    return filtered_df, cat_map, color_map


# ============================================================
# 2. å®šç¾© Dataset é¡åˆ¥
# ============================================================

class ClothingDataset(Dataset):
    """æœè£åœ–ç‰‡è³‡æ–™é›†"""
    def __init__(self, dataframe, transform=None, image_folder="images"):
        self.df = dataframe
        self.transform = transform
        self.image_folder = image_folder

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_id = int(row['id'])
        img_path = os.path.join(self.image_folder, f"{img_id}.jpg")

        try:
            image = Image.open(img_path).convert('RGB')
        except:
            # è‹¥åœ–ç‰‡ä¸å­˜åœ¨ï¼Œè¿”å›é›¶å¼µé‡
            return torch.zeros(3, 224, 224), 0, 0

        if self.transform:
            image = self.transform(image)
        
        return image, int(row['cat_label']), int(row['color_label'])


# ============================================================
# 3. å®šç¾©æ¨¡å‹
# ============================================================

class MultiHeadResNet(nn.Module):
    """å¤šé ­ ResNet æ¨¡å‹ (åˆ†é¡åˆ¥å’Œé¡è‰²)"""
    def __init__(self, num_cats, num_cols):
        super().__init__()
        self.backbone = models.resnet18(pretrained=True)
        num_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Identity()
        self.fc_cat = nn.Linear(num_features, num_cats)
        self.fc_color = nn.Linear(num_features, num_cols)

    def forward(self, x):
        features = self.backbone(x)
        return self.fc_cat(features), self.fc_color(features)


# ============================================================
# 4. è¨“ç·´å‡½æ•¸
# ============================================================

def train_model(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=1):
    """è¨“ç·´æ¨¡å‹ä¸¦é©—è­‰"""
    train_losses = []
    val_losses = []
    
    print("é–‹å§‹è¨“ç·´...")
    
    for epoch in range(num_epochs):
        # ========== è¨“ç·´éšæ®µ ==========
        model.train()
        epoch_train_loss = 0
        print(f"\nEpoch {epoch + 1}/{num_epochs}")
        
        for i, (imgs, cats, cols) in enumerate(train_loader):
            imgs = imgs.to(device)
            cats = cats.to(device).long()
            cols = cols.to(device).long()

            optimizer.zero_grad()
            out_cat, out_col = model(imgs)
            loss = criterion(out_cat, cats) + criterion(out_col, cols)
            loss.backward()
            optimizer.step()

            epoch_train_loss += loss.item()
            train_losses.append(loss.item())

            if i % 50 == 0:
                print(f"Step [{i}/{len(train_loader)}], Loss: {loss.item():.4f}")

        # ========== é©—è­‰éšæ®µ ==========
        model.eval()
        epoch_val_loss = 0
        val_count = 0
        
        with torch.no_grad():
            for imgs, cats, cols in val_loader:
                imgs = imgs.to(device)
                cats = cats.to(device).long()
                cols = cols.to(device).long()

                out_cat, out_col = model(imgs)
                loss = criterion(out_cat, cats) + criterion(out_col, cols)
                
                epoch_val_loss += loss.item()
                val_losses.append(loss.item())
                val_count += 1

        avg_train_loss = epoch_train_loss / len(train_loader)
        avg_val_loss = epoch_val_loss / val_count
        
        print(f"å¹³å‡è¨“ç·´ Loss: {avg_train_loss:.4f}")
        print(f"å¹³å‡é©—è­‰ Loss: {avg_val_loss:.4f}")

    print("ğŸ‰ è¨“ç·´å®Œæˆï¼")
    return train_losses, val_losses


# ============================================================
# 5. å¯è¦–åŒ–æå¤±æ›²ç·š
# ============================================================

def plot_loss_curve(train_losses, val_losses):
    """ç¹ªè£½è¨“ç·´å’Œé©—è­‰æå¤±æ›²ç·š"""
    plt.figure(figsize=(12, 5))
    
    plt.plot(train_losses, label='Training Loss', color='blue', alpha=0.7)
    plt.plot(val_losses, label='Validation Loss', color='red', alpha=0.7)
    plt.title('Training vs Validation Loss Curve')
    plt.xlabel('Steps')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig('loss_curve.png', dpi=150)
    print("Loss æ›²ç·šå·²ä¿å­˜ç‚º loss_curve.png")
    plt.show()


# ============================================================
# 6. é æ¸¬å‡½æ•¸
# ============================================================

def predict_image(model, image_path, transform, cat_map, color_map, device):
    """é æ¸¬å–®å¼µåœ–ç‰‡çš„åˆ†é¡å’Œé¡è‰²"""
    model.eval()
    
    try:
        img = Image.open(image_path).convert('RGB')
        input_tensor = transform(img).unsqueeze(0).to(device)

        with torch.no_grad():
            p_cat, p_col = model(input_tensor)
            cat_res = cat_map[torch.argmax(p_cat).item()]
            col_res = color_map[torch.argmax(p_col).item()]

        plt.imshow(img)
        plt.axis('off')
        plt.title(f"{col_res} {cat_res}")
        plt.show()
        
        print(f"é æ¸¬çµæœ: {col_res} {cat_res}")
    except FileNotFoundError:
        print(f"åœ–ç‰‡ä¸å­˜åœ¨: {image_path}")


# ============================================================
# 7. ä¸»ç¨‹åº
# ============================================================

def main():
    """ä¸»å‡½æ•¸"""
    # æª¢æŸ¥è¨­å‚™
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ ä½¿ç”¨è£ç½®: {device}")
    if device.type == "cuda":
        print(f"   GPU å‹è™Ÿ: {torch.cuda.get_device_name(0)}")
    
    # ä¸‹è¼‰è³‡æ–™
    setup_kaggle_and_download()
    
    # æº–å‚™è³‡æ–™
    filtered_df, cat_map, color_map = load_and_prepare_data()
    
    # å®šç¾©è½‰æ›
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    # å»ºç«‹æ¨¡å‹
    model = MultiHeadResNet(len(cat_map), len(color_map)).to(device)
    
    # æª¢æŸ¥æ˜¯å¦æœ‰å·²ä¿å­˜çš„æ¨¡å‹
    if os.path.exists('model_weights.pth'):
        print("âœ… æ‰¾åˆ°å·²è¨“ç·´çš„æ¨¡å‹ï¼Œç›´æ¥è¼‰å…¥...")
        model.load_state_dict(torch.load('model_weights.pth', map_location=device))
    else:
        print("ğŸ”„ æœªæ‰¾åˆ°æ¨¡å‹ï¼Œé–‹å§‹è¨“ç·´...")
        
        # æº–å‚™ DataLoader
        full_dataset = ClothingDataset(filtered_df, transform=transform)
        
        # åˆ†å‰²è¨“ç·´é›†å’Œé©—è­‰é›† (80:20)
        train_size = int(0.8 * len(full_dataset))
        val_size = len(full_dataset) - train_size
        train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])
        
        print(f"è¨“ç·´é›†: {train_size}, é©—è­‰é›†: {val_size}")
        
        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
        
        # è¨“ç·´è¨­å®š
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.CrossEntropyLoss()
        
        # è¨“ç·´æ¨¡å‹
        train_losses, val_losses = train_model(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=1)
        
        # å¯è¦–åŒ–æå¤±
        plot_loss_curve(train_losses, val_losses)
        
        # ä¿å­˜æ¨¡å‹
        torch.save(model.state_dict(), 'model_weights.pth')
        print("æ¨¡å‹å·²ä¿å­˜ç‚º model_weights.pth")
    
    # é¸æ“‡æ€§: æ¸¬è©¦é æ¸¬ (éœ€è¦æä¾›åœ–ç‰‡è·¯å¾‘)
    predict_image(model, "input/red_sweater.jpg", transform, cat_map, color_map, device)


if __name__ == "__main__":
    main()
